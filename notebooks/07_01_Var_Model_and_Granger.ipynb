{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eea7246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "267a31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load sentiment and whale data, parsing correct date columns\n",
    "sentiment = pd.read_csv('../data/cleaned/unified_crypto_sentiment_2024_2025.csv', parse_dates=['timestamp'])\n",
    "whales = pd.read_csv('../data/cleaned/whale_activity_2024_2025_sorted.csv', parse_dates=['time_range'])\n",
    "\n",
    "# 2. Create a clean date column (date only, not time)\n",
    "sentiment['date'] = sentiment['timestamp'].dt.date\n",
    "whales['date'] = whales['time_range'].dt.date\n",
    "\n",
    "# Now you can proceed with the next steps (filtering, merging, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5e7a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Aggregate Data to Daily Level\n",
    "# Aggregate sentiment (mean per day per coin)\n",
    "sentiment_daily = sentiment.groupby(['coin', 'date']).agg({\n",
    "    'sentiment': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Aggregate whale data (sum per day per coin)\n",
    "whales_daily = whales.groupby(['coin', 'date']).agg({\n",
    "    'whale_transaction_count': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6994b",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "You’re smoothing your data to a daily frequency.\n",
    "\n",
    "sentiment: mean value of all posts/tweets per day per coin.\n",
    "\n",
    "whale_transaction_count: total (sum) of whale transactions per day per coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b26cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Merge Sentiment and Whale Activity\n",
    "merged = pd.merge(sentiment_daily, whales_daily, on=['coin', 'date'], how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e61b1",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "You want both sentiment and whale activity in the same row for each (coin, date).\n",
    "\n",
    "Use inner join to only keep days that have both sentiment and whale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9f403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Choose the Coin and Create a Time Series: VAR models require one time series dataframe per coin.\n",
    "\n",
    "# Let's use BTC as an example\n",
    "btc_df = merged[merged['coin'] == 'BTC'].sort_values('date').set_index('date')\n",
    "btc_df = btc_df[['sentiment', 'whale_transaction_count']]\n",
    "btc_df = btc_df.dropna()  # Remove any missing days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ca98b",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "Filter for just BTC (or any coin you want).\n",
    "\n",
    "Sort by date and set date as index for time series analysis.\n",
    "\n",
    "Keep only needed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "408dc931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC Sentiment - p-value: 0.0\n",
      "BTC Sentiment is stationary.\n",
      "BTC Whale Tx - p-value: 0.0011356381627508358\n",
      "BTC Whale Tx is stationary.\n"
     ]
    }
   ],
   "source": [
    "#4. (Optional but Recommended) Check Stationarity\n",
    "\"\"\"\n",
    "VAR models need stationary time series.\n",
    "You might need to difference the series if they are not stationary.\n",
    "\"\"\"\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"{name} - p-value: {result[1]}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(f\"{name} is stationary.\")\n",
    "    else:\n",
    "        print(f\"{name} is NOT stationary. Consider differencing.\")\n",
    "\n",
    "# Check both columns\n",
    "check_stationarity(btc_df['sentiment'], 'BTC Sentiment')\n",
    "check_stationarity(btc_df['whale_transaction_count'], 'BTC Whale Tx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced851e",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "A p-value < 0.05 means the series is stationary (good).\n",
    "\n",
    "If not stationary, you can difference it (df.diff().dropna())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc220534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat does \"stationary\" mean in time series analysis?\\nStationary means that the properties of the data (like the mean, variance, and correlations) do not change over time.\\n\\nImagine you measure the temperature in your city every day. If the average and how much it bounces up and down stay \\nthe same throughout the year, the series is stationary.\\n\\nBut if the temperature clearly goes up in the summer and down in the winter (trend or seasonality), it’s not stationary.\\n\\nWhy do we care if data is stationary?\\nMany time series models (like VAR and Granger Causality) require the data to be stationary for the math to work correctly \\nand the predictions to be reliable.\\n\\nIf the data is not stationary, the results of your model could be misleading.\\n\\nWhat is the code doing?\\nadfuller is a test (Augmented Dickey-Fuller test) that checks if your series is stationary.\\n\\nIf the p-value from the test is less than 0.05, the series is considered stationary.\\n\\nYour Output (step 4):\\nBTC Sentiment - p-value: 0.0\\nBTC Sentiment is stationary.\\n\\nBTC Whale Tx - p-value: 0.0011\\nBTC Whale Tx is stationary.\\n\\nWhat does this mean?\\n\\nBoth your Bitcoin sentiment series and Bitcoin whale transaction count series have properties that stay consistent\\n over time (at least according to this test).\\n\\nYou do not need to transform (\"difference\") your data before modeling. You can continue with VAR or Granger Causality tests directly.\\n\\nSummary (Simple Version)\\nStationary = stable and predictable over time.\\n\\nYou want stationary data for time series modeling.\\n\\nYour test says both of your series are stationary, so you’re good to go!\\n\\nIf you want a simple analogy:\\nA stationary series is like a calm lake — always the same on average, with waves (variations) that don’t change their size or pattern over time.\\nA non-stationary series is like a river that keeps rising or falling or changing its speed — it’s unpredictable.\\n\\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What does \"stationary\" mean in time series analysis?\n",
    "Stationary means that the properties of the data (like the mean, variance, and correlations) do not change over time.\n",
    "\n",
    "Imagine you measure the temperature in your city every day. If the average and how much it bounces up and down stay \n",
    "the same throughout the year, the series is stationary.\n",
    "\n",
    "But if the temperature clearly goes up in the summer and down in the winter (trend or seasonality), it’s not stationary.\n",
    "\n",
    "Why do we care if data is stationary?\n",
    "Many time series models (like VAR and Granger Causality) require the data to be stationary for the math to work correctly \n",
    "and the predictions to be reliable.\n",
    "\n",
    "If the data is not stationary, the results of your model could be misleading.\n",
    "\n",
    "What is the code doing?\n",
    "adfuller is a test (Augmented Dickey-Fuller test) that checks if your series is stationary.\n",
    "\n",
    "If the p-value from the test is less than 0.05, the series is considered stationary.\n",
    "\n",
    "Your Output (step 4):\n",
    "BTC Sentiment - p-value: 0.0\n",
    "BTC Sentiment is stationary.\n",
    "\n",
    "BTC Whale Tx - p-value: 0.0011\n",
    "BTC Whale Tx is stationary.\n",
    "\n",
    "What does this mean?\n",
    "\n",
    "Both your Bitcoin sentiment series and Bitcoin whale transaction count series have properties that stay consistent\n",
    " over time (at least according to this test).\n",
    "\n",
    "You do not need to transform (\"difference\") your data before modeling. You can continue with VAR or Granger Causality tests directly.\n",
    "\n",
    "Summary (Simple Version)\n",
    "Stationary = stable and predictable over time.\n",
    "\n",
    "You want stationary data for time series modeling.\n",
    "\n",
    "Your test says both of your series are stationary, so you’re good to go!\n",
    "\n",
    "If you want a simple analogy:\n",
    "A stationary series is like a calm lake — always the same on average, with waves (variations) that don’t change their size or pattern over time.\n",
    "A non-stationary series is like a river that keeps rising or falling or changing its speed — it’s unpredictable.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f82d26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VAR Order Selection (* highlights the minimums)  \n",
      "==================================================\n",
      "       AIC         BIC         FPE         HQIC   \n",
      "--------------------------------------------------\n",
      "0        4.614       4.632       100.8       4.621\n",
      "1        4.380      4.436*       79.87       4.402\n",
      "2        4.386       4.479       80.36       4.423\n",
      "3        4.397       4.527       81.23       4.448\n",
      "4        4.361       4.527       78.34       4.427\n",
      "5        4.282       4.485       72.39       4.362\n",
      "6        4.228       4.468       68.57       4.323\n",
      "7       4.199*       4.476      66.59*      4.308*\n",
      "8        4.207       4.521       67.15       4.331\n",
      "9        4.216       4.567       67.76       4.354\n",
      "10       4.208       4.596       67.25       4.361\n",
      "11       4.220       4.645       68.02       4.387\n",
      "12       4.236       4.698       69.12       4.418\n",
      "13       4.251       4.750       70.17       4.447\n",
      "14       4.262       4.798       70.95       4.473\n",
      "15       4.273       4.846       71.79       4.499\n",
      "--------------------------------------------------\n",
      "Best lag according to AIC: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\crypto-nlp\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "#5. Select Optimal Lag Using AIC\n",
    "#Find the optimal lag length for your VAR model using AIC.\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "model = VAR(btc_df)\n",
    "order_results = model.select_order(15)  # test up to 15 lags\n",
    "print(order_results.summary())\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "aic = order_results.aic\n",
    "if isinstance(aic, (np.ndarray, list)):\n",
    "    best_lag = np.nanargmin(aic)\n",
    "elif hasattr(aic, 'idxmin'):\n",
    "    best_lag = aic.idxmin()\n",
    "else:\n",
    "    best_lag = aic\n",
    "print(\"Best lag according to AIC:\", best_lag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89c39f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Fri, 01, Aug, 2025\n",
      "Time:                     18:25:19\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                    4.46283\n",
      "Nobs:                     451.000    HQIC:                   4.29712\n",
      "Log likelihood:          -2194.58    FPE:                    65.9825\n",
      "AIC:                      4.18934    Det(Omega_mle):         61.8031\n",
      "--------------------------------------------------------------------\n",
      "Results for equation sentiment\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                              0.112966         0.185218            0.610           0.542\n",
      "L1.sentiment                       0.117847         0.047896            2.460           0.014\n",
      "L1.whale_transaction_count         0.000580         0.000609            0.952           0.341\n",
      "L2.sentiment                       0.035766         0.048337            0.740           0.459\n",
      "L2.whale_transaction_count        -0.001388         0.000628           -2.209           0.027\n",
      "L3.sentiment                      -0.024718         0.048072           -0.514           0.607\n",
      "L3.whale_transaction_count         0.000160         0.000618            0.259           0.796\n",
      "L4.sentiment                       0.085226         0.047799            1.783           0.075\n",
      "L4.whale_transaction_count         0.000737         0.000619            1.190           0.234\n",
      "L5.sentiment                       0.091442         0.047955            1.907           0.057\n",
      "L5.whale_transaction_count        -0.000625         0.000614           -1.017           0.309\n",
      "L6.sentiment                      -0.023758         0.048591           -0.489           0.625\n",
      "L6.whale_transaction_count        -0.000026         0.000622           -0.041           0.967\n",
      "L7.sentiment                       0.049728         0.048170            1.032           0.302\n",
      "L7.whale_transaction_count         0.000772         0.000599            1.290           0.197\n",
      "=============================================================================================\n",
      "\n",
      "Results for equation whale_transaction_count\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                             49.397517        14.236017            3.470           0.001\n",
      "L1.sentiment                       4.902287         3.681347            1.332           0.183\n",
      "L1.whale_transaction_count         0.304065         0.046817            6.495           0.000\n",
      "L2.sentiment                       3.803265         3.715238            1.024           0.306\n",
      "L2.whale_transaction_count         0.018155         0.048297            0.376           0.707\n",
      "L3.sentiment                       0.965459         3.694879            0.261           0.794\n",
      "L3.whale_transaction_count        -0.112312         0.047476           -2.366           0.018\n",
      "L4.sentiment                      -7.924829         3.673891           -2.157           0.031\n",
      "L4.whale_transaction_count         0.054259         0.047576            1.140           0.254\n",
      "L5.sentiment                     -12.245171         3.685892           -3.322           0.001\n",
      "L5.whale_transaction_count         0.141061         0.047225            2.987           0.003\n",
      "L6.sentiment                       4.072158         3.734765            1.090           0.276\n",
      "L6.whale_transaction_count         0.177161         0.047801            3.706           0.000\n",
      "L7.sentiment                       0.335116         3.702398            0.091           0.928\n",
      "L7.whale_transaction_count         0.204955         0.046008            4.455           0.000\n",
      "=============================================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "                           sentiment  whale_transaction_count\n",
      "sentiment                   1.000000                -0.003487\n",
      "whale_transaction_count    -0.003487                 1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\crypto-nlp\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "#Var Results Summary\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "#Fit the VAR model\n",
    "var_model = VAR(btc_df[['sentiment', 'whale_transaction_count']])\n",
    "var_results = var_model.fit(best_lag)\n",
    "\n",
    "# View summary\n",
    "print(var_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f182f",
   "metadata": {},
   "source": [
    "Interpretation of results in Doc of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58ffed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality F-test. H_0: whale_transaction_count does not Granger-cause sentiment. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "==============================================\n",
      "Test statistic Critical value p-value    df   \n",
      "----------------------------------------------\n",
      "         1.024          2.020   0.413 (7, 872)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6. Fit VAR model and test Granger\n",
    "results = model.fit(7)\n",
    "\n",
    "# Granger causality: does whale_tx predict sentiment?\n",
    "print(results.test_causality('sentiment', ['whale_transaction_count'], kind='f').summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e802c",
   "metadata": {},
   "source": [
    "This code builds a statistical model that explains how BTC sentiment and whale transactions influence each other over time, using as many past days as the lag you found optimal.\n",
    "\n",
    "The printed summary helps you see:\n",
    "\n",
    "How strong is the influence from past sentiment/whale transactions?\n",
    "\n",
    "Which lagged variables are significant?\n",
    "\n",
    "Overall, how well does the model fit your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d13e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality F-test. H_0: sentiment does not Granger-cause whale_transaction_count. Conclusion: reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "         2.977          2.020   0.004 (7, np.int64(872))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ALTERVANTIVE: Test if SENTIMENT Granger-causes WHALE TRANSACTION COUNT (BTC)\n",
    "print(var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f').summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5abb7b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0043\n",
      "Conclusion: Sentiment Granger-causes whale_transaction_count (p < 0.05).\n",
      "There is statistically significant evidence that sentiment helps predict future whale activity.\n",
      "Granger causality F-test. H_0: sentiment does not Granger-cause whale_transaction_count. Conclusion: reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "         2.977          2.020   0.004 (7, np.int64(872))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Granger causality test: Does X Granger-cause Y?\n",
    "test_result = var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f')\n",
    "\n",
    "# Extract the p-value\n",
    "pval = test_result.pvalue\n",
    "\n",
    "print(f\"P-value: {pval:.4f}\")\n",
    "\n",
    "if pval < 0.05:\n",
    "    print(\"Conclusion: Sentiment Granger-causes whale_transaction_count (p < 0.05).\")\n",
    "    print(\"There is statistically significant evidence that sentiment helps predict future whale activity.\")\n",
    "else:\n",
    "    print(\"Conclusion: Sentiment does NOT Granger-cause whale_transaction_count (p >= 0.05).\")\n",
    "    print(\"There is no evidence that sentiment helps predict future whale activity.\")\n",
    "\n",
    "# Optionally print test statistic, degrees of freedom, etc.\n",
    "print(test_result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9746322",
   "metadata": {},
   "source": [
    "The Granger causality test showed that past sentiment values are useful for predicting future whale transaction counts (p = 0.004 < 0.05), indicating that sentiment leads or influences whale activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAR Model and Granger test for ETH\n",
    "#1. Filter Data for Each Coin\n",
    "\n",
    "eth_sentiment = sentiment[sentiment['coin'] == 'ETH'].copy()\n",
    "eth_whales = whales[whales['coin'] == 'ETH'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82db8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Aggregate Daily Data & Merge\n",
    "# Aggregate sentiment: mean per day\n",
    "eth_sentiment_daily = eth_sentiment.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Aggregate whale tx: sum per day\n",
    "eth_whales_daily = eth_whales.groupby('date')['whale_transaction_count'].sum().reset_index()\n",
    "\n",
    "# Merge on date (inner join ensures only matching dates)\n",
    "eth_df = pd.merge(eth_sentiment_daily, eth_whales_daily, on='date').sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d6d9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH Sentiment - p-value: 2.6020971546726496e-23\n",
      "ETH Sentiment is stationary.\n",
      "ETH Whale Tx - p-value: 0.013039386332168558\n",
      "ETH Whale Tx is stationary.\n"
     ]
    }
   ],
   "source": [
    "#3. Check Stationarity\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"{name} - p-value: {result[1]}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(f\"{name} is stationary.\")\n",
    "    else:\n",
    "        print(f\"{name} is NOT stationary. Consider differencing.\")\n",
    "\n",
    "check_stationarity(eth_df['sentiment'], 'ETH Sentiment')\n",
    "check_stationarity(eth_df['whale_transaction_count'], 'ETH Whale Tx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What does \"stationary\" mean in time series analysis?\n",
    "Stationary means that the properties of the data (like the mean, variance, and correlations) do not change over time.\n",
    "\n",
    "Imagine you measure the temperature in your city every day. If the average and how much it bounces up and down stay \n",
    "the same throughout the year, the series is stationary.\n",
    "\n",
    "But if the temperature clearly goes up in the summer and down in the winter (trend or seasonality), it’s not stationary.\n",
    "\n",
    "Why do we care if data is stationary?\n",
    "Many time series models (like VAR and Granger Causality) require the data to be stationary for the math to work correctly \n",
    "and the predictions to be reliable.\n",
    "\n",
    "If the data is not stationary, the results of your model could be misleading.\n",
    "\n",
    "What is the code doing?\n",
    "adfuller is a test (Augmented Dickey-Fuller test) that checks if your series is stationary.\n",
    "\n",
    "If the p-value from the test is less than 0.05, the series is considered stationary.\n",
    "\n",
    "\n",
    "A stationary time series is one whose statistical properties, such as mean, variance, and autocorrelation,\n",
    " do not change over time. This means the series exhibits a constant behavior, regardless of the time period observed. \n",
    " In simpler terms, the series fluctuates around a constant mean, with a constant variance, and its autocorrelation structure \n",
    " depends only on the time lag, not the specific time period. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "611718ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lag for ETH according to AIC: 10\n"
     ]
    }
   ],
   "source": [
    "#4. Select Optimal Lag Using AIC\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "model = VAR(eth_df[['sentiment', 'whale_transaction_count']])\n",
    "order_results = model.select_order(15)\n",
    "import numpy as np\n",
    "\n",
    "aic = order_results.aic\n",
    "if isinstance(aic, (np.ndarray, list)):\n",
    "    best_lag = np.nanargmin(aic)\n",
    "elif hasattr(aic, 'idxmin'):\n",
    "    best_lag = aic.idxmin()\n",
    "else:\n",
    "    best_lag = aic\n",
    "print(\"Best lag for ETH according to AIC:\", best_lag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80b94be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Sat, 02, Aug, 2025\n",
      "Time:                     10:52:28\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                    6.44567\n",
      "Nobs:                     434.000    HQIC:                   6.20709\n",
      "Log likelihood:          -2502.82    FPE:                    424.816\n",
      "AIC:                      6.05150    Det(Omega_mle):         386.507\n",
      "--------------------------------------------------------------------\n",
      "Results for equation sentiment\n",
      "==============================================================================================\n",
      "                                 coefficient       std. error           t-stat            prob\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                               0.118471         0.099311            1.193           0.233\n",
      "L1.sentiment                        0.104248         0.048979            2.128           0.033\n",
      "L1.whale_transaction_count          0.000128         0.000281            0.458           0.647\n",
      "L2.sentiment                        0.102599         0.049160            2.087           0.037\n",
      "L2.whale_transaction_count          0.000141         0.000324            0.434           0.665\n",
      "L3.sentiment                        0.000557         0.049400            0.011           0.991\n",
      "L3.whale_transaction_count         -0.000089         0.000325           -0.273           0.785\n",
      "L4.sentiment                        0.046085         0.049375            0.933           0.351\n",
      "L4.whale_transaction_count         -0.000119         0.000326           -0.366           0.714\n",
      "L5.sentiment                       -0.010033         0.049361           -0.203           0.839\n",
      "L5.whale_transaction_count         -0.000003         0.000329           -0.010           0.992\n",
      "L6.sentiment                        0.026760         0.049276            0.543           0.587\n",
      "L6.whale_transaction_count          0.000204         0.000326            0.626           0.531\n",
      "L7.sentiment                        0.025137         0.049208            0.511           0.609\n",
      "L7.whale_transaction_count         -0.000047         0.000335           -0.139           0.889\n",
      "L8.sentiment                        0.015851         0.048582            0.326           0.744\n",
      "L8.whale_transaction_count         -0.000351         0.000334           -1.051           0.293\n",
      "L9.sentiment                        0.076487         0.048366            1.581           0.114\n",
      "L9.whale_transaction_count          0.000003         0.000334            0.008           0.993\n",
      "L10.sentiment                       0.016641         0.048364            0.344           0.731\n",
      "L10.whale_transaction_count         0.000248         0.000325            0.762           0.446\n",
      "==============================================================================================\n",
      "\n",
      "Results for equation whale_transaction_count\n",
      "==============================================================================================\n",
      "                                 coefficient       std. error           t-stat            prob\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                             121.512834        17.234274            7.051           0.000\n",
      "L1.sentiment                        5.315215         8.499784            0.625           0.532\n",
      "L1.whale_transaction_count          0.584490         0.048691           12.004           0.000\n",
      "L2.sentiment                       -2.410457         8.531117           -0.283           0.778\n",
      "L2.whale_transaction_count          0.155383         0.056261            2.762           0.006\n",
      "L3.sentiment                        8.765128         8.572748            1.022           0.307\n",
      "L3.whale_transaction_count         -0.091621         0.056426           -1.624           0.104\n",
      "L4.sentiment                        6.378949         8.568423            0.744           0.457\n",
      "L4.whale_transaction_count          0.062279         0.056498            1.102           0.270\n",
      "L5.sentiment                       -7.473560         8.566098           -0.872           0.383\n",
      "L5.whale_transaction_count          0.148776         0.057071            2.607           0.009\n",
      "L6.sentiment                        7.275384         8.551312            0.851           0.395\n",
      "L6.whale_transaction_count          0.173574         0.056608            3.066           0.002\n",
      "L7.sentiment                       -0.322894         8.539418           -0.038           0.970\n",
      "L7.whale_transaction_count          0.043839         0.058144            0.754           0.451\n",
      "L8.sentiment                       -4.668953         8.430901           -0.554           0.580\n",
      "L8.whale_transaction_count         -0.156645         0.057931           -2.704           0.007\n",
      "L9.sentiment                        8.496182         8.393285            1.012           0.311\n",
      "L9.whale_transaction_count         -0.181732         0.057958           -3.136           0.002\n",
      "L10.sentiment                      17.515060         8.392949            2.087           0.037\n",
      "L10.whale_transaction_count        -0.121063         0.056483           -2.143           0.032\n",
      "==============================================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "                           sentiment  whale_transaction_count\n",
      "sentiment                   1.000000                 0.013836\n",
      "whale_transaction_count     0.013836                 1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5  Fit the VAR Model\n",
    "\n",
    "var_model = VAR(eth_df[['sentiment', 'whale_transaction_count']])\n",
    "var_results = var_model.fit(10)\n",
    "print(var_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea77c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH: Whale Granger-causes Sentiment p-value: 0.9917\n",
      "Whale activity does NOT help predict sentiment.\n",
      "Granger causality F-test. H_0: whale_transaction_count does not Granger-cause sentiment. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "===============================================\n",
      "Test statistic Critical value p-value     df   \n",
      "-----------------------------------------------\n",
      "        0.2432          1.842   0.992 (10, 826)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6. Granger Causality Tests (Both Directions)\n",
    "#(A) Test if Whale Tx Granger-causes Sentiment\n",
    "test_result = var_results.test_causality('sentiment', ['whale_transaction_count'], kind='f')\n",
    "pval = test_result.pvalue\n",
    "print(f\"ETH: Whale Granger-causes Sentiment p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Whale activity helps predict sentiment (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Whale activity does NOT help predict sentiment.\")\n",
    "print(test_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f3eb524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH: Sentiment Granger-causes Whale p-value: 0.4201\n",
      "Sentiment does NOT help predict whale activity.\n",
      "Granger causality F-test. H_0: sentiment does not Granger-cause whale_transaction_count. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "===============================================\n",
      "Test statistic Critical value p-value     df   \n",
      "-----------------------------------------------\n",
      "         1.025          1.842   0.420 (10, 826)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#(B) Test if Sentiment Granger-causes Whale Tx\n",
    "test_result = var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f')\n",
    "pval = test_result.pvalue\n",
    "print(f\"ETH: Sentiment Granger-causes Whale p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Sentiment helps predict whale activity (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Sentiment does NOT help predict whale activity.\")\n",
    "print(test_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1adff614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInterpretation: \\n1. Granger Causality Test 1:\\nTested: Does sentiment Granger-cause (help predict) whale activity for ETH?\\n\\np-value: 0.4201 (which is greater than 0.05)\\n\\nConclusion:\\n\\nWe fail to reject the null hypothesis (H₀): “Sentiment does not help predict whale activity.”\\n\\nInterpretation: There is no statistical evidence that past sentiment data improves prediction of future whale transactions for ETH.\\n\\nIn simple terms: Retail sentiment (tweets, etc.) does NOT help predict when ETH whales will move.\\n\\n2. Granger Causality Test 2:\\nTested: Does whale activity Granger-cause (help predict) sentiment for ETH?\\n\\np-value: 0.420 (again, greater than 0.05)\\n\\nConclusion:\\n\\nWe fail to reject the null hypothesis (H₀): “Whale activity does not help predict sentiment.”\\n\\nInterpretation: There is no statistical evidence that past whale transactions improve prediction of future sentiment for ETH.\\n\\nIn simple terms: Whale transactions for ETH do NOT lead to noticeable changes in public sentiment (as measured by Twitter) in the following days.\\nFor my thesis:\\nFor Ethereum (ETH), Granger causality analysis reveals that neither retail sentiment nor whale transaction activity Granger-cause one another.\\nThe p-values in both directions were well above the conventional significance threshold (p > 0.05), indicating a lack of predictive causality.\\n In practical terms, this suggests that changes in public sentiment do not systematically precede or follow large whale transactions in ETH, \\n at least not in the timeframes and data windows tested.\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Interpretation: \n",
    "1. Granger Causality Test 1:\n",
    "Tested: Does sentiment Granger-cause (help predict) whale activity for ETH?\n",
    "\n",
    "p-value: 0.4201 (which is greater than 0.05)\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "We fail to reject the null hypothesis (H₀): “Sentiment does not help predict whale activity.”\n",
    "\n",
    "Interpretation: There is no statistical evidence that past sentiment data improves prediction of future whale transactions for ETH.\n",
    "\n",
    "In simple terms: Retail sentiment (tweets, etc.) does NOT help predict when ETH whales will move.\n",
    "\n",
    "2. Granger Causality Test 2:\n",
    "Tested: Does whale activity Granger-cause (help predict) sentiment for ETH?\n",
    "\n",
    "p-value: 0.420 (again, greater than 0.05)\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "We fail to reject the null hypothesis (H₀): “Whale activity does not help predict sentiment.”\n",
    "\n",
    "Interpretation: There is no statistical evidence that past whale transactions improve prediction of future sentiment for ETH.\n",
    "\n",
    "In simple terms: Whale transactions for ETH do NOT lead to noticeable changes in public sentiment (as measured by Twitter) in the following days.\n",
    "For my thesis:\n",
    "For Ethereum (ETH), Granger causality analysis reveals that neither retail sentiment nor whale transaction activity Granger-cause one another.\n",
    "The p-values in both directions were well above the conventional significance threshold (p > 0.05), indicating a lack of predictive causality.\n",
    " In practical terms, this suggests that changes in public sentiment do not systematically precede or follow large whale transactions in ETH, \n",
    " at least not in the timeframes and data windows tested.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "412eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAR Model and Granger test for ADA (Cardano)\n",
    "# 1. Filter Data for Each Coin\n",
    "\n",
    "ada_sentiment = sentiment[sentiment['coin'] == 'ADA'].copy()\n",
    "ada_whales = whales[whales['coin'] == 'ADA'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0e83221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Aggregate Daily Data & Merge\n",
    "# Aggregate sentiment: mean per day\n",
    "ada_sentiment_daily = ada_sentiment.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Aggregate whale tx: sum per day\n",
    "ada_whales_daily = ada_whales.groupby('date')['whale_transaction_count'].sum().reset_index()\n",
    "\n",
    "# Merge on date (inner join ensures only matching dates)\n",
    "ada_df = pd.merge(ada_sentiment_daily, ada_whales_daily, on='date').sort_values('date').reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc649efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA Sentiment - p-value: 0.0006508223903875885\n",
      "ADA Sentiment is stationary.\n",
      "ADA Whale Tx - p-value: 1.1338723807140113e-07\n",
      "ADA Whale Tx is stationary.\n"
     ]
    }
   ],
   "source": [
    "#3. Check Stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"{name} - p-value: {result[1]}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(f\"{name} is stationary.\")\n",
    "    else:\n",
    "        print(f\"{name} is NOT stationary. Consider differencing.\")\n",
    "\n",
    "# Check for ADA\n",
    "check_stationarity(ada_df['sentiment'], 'ADA Sentiment')\n",
    "check_stationarity(ada_df['whale_transaction_count'], 'ADA Whale Tx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42a08d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lag for ADA according to AIC: 1\n"
     ]
    }
   ],
   "source": [
    "#4. Select Optimal Lag Using AIC\n",
    "from statsmodels.tsa.api import VAR\n",
    "import numpy as np\n",
    "\n",
    "model = VAR(ada_df[['sentiment', 'whale_transaction_count']])\n",
    "order_results = model.select_order(15)\n",
    "aic = order_results.aic\n",
    "if isinstance(aic, (np.ndarray, list)):\n",
    "    best_lag = np.nanargmin(aic)\n",
    "elif hasattr(aic, 'idxmin'):\n",
    "    best_lag = aic.idxmin()\n",
    "else:\n",
    "    best_lag = aic\n",
    "print(\"Best lag for ADA according to AIC:\", best_lag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8d93d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Sat, 02, Aug, 2025\n",
      "Time:                     11:22:00\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                    3.68329\n",
      "Nobs:                     372.000    HQIC:                   3.64518\n",
      "Log likelihood:          -1723.02    FPE:                    37.3405\n",
      "AIC:                      3.62008    Det(Omega_mle):         36.7455\n",
      "--------------------------------------------------------------------\n",
      "Results for equation sentiment\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                              0.211986         0.094739            2.238           0.025\n",
      "L1.sentiment                       0.098426         0.052055            1.891           0.059\n",
      "L1.whale_transaction_count         0.000482         0.001203            0.401           0.689\n",
      "=============================================================================================\n",
      "\n",
      "Results for equation whale_transaction_count\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                             65.973487         4.069224           16.213           0.000\n",
      "L1.sentiment                      -0.620041         2.235868           -0.277           0.782\n",
      "L1.whale_transaction_count         0.147193         0.051651            2.850           0.004\n",
      "=============================================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "                           sentiment  whale_transaction_count\n",
      "sentiment                   1.000000                 0.084400\n",
      "whale_transaction_count     0.084400                 1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. Fit the VAR Model\n",
    "var_model = VAR(ada_df[['sentiment', 'whale_transaction_count']])\n",
    "var_results = var_model.fit(best_lag)\n",
    "print(var_results.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "daaf23f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA: Whale Granger-causes Sentiment p-value: 0.6887\n",
      "Whale activity does NOT help predict sentiment.\n",
      "Granger causality F-test. H_0: whale_transaction_count does not Granger-cause sentiment. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "        0.1606          3.854   0.689 (1, np.int64(738))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6. Granger Causality Tests (Both Directions)\n",
    "#A. Whale Tx → Sentiment\n",
    "test_result = var_results.test_causality('sentiment', ['whale_transaction_count'], kind='f')\n",
    "pval = test_result.pvalue\n",
    "print(f\"ADA: Whale Granger-causes Sentiment p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Whale activity helps predict sentiment (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Whale activity does NOT help predict sentiment.\")\n",
    "print(test_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1962435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA: Sentiment Granger-causes Whale p-value: 0.7816\n",
      "Sentiment does NOT help predict whale activity.\n",
      "Granger causality F-test. H_0: sentiment does not Granger-cause whale_transaction_count. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "       0.07690          3.854   0.782 (1, np.int64(738))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#B. Sentiment → Whale Tx\n",
    "test_result = var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f')\n",
    "pval = test_result.pvalue\n",
    "print(f\"ADA: Sentiment Granger-causes Whale p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Sentiment helps predict whale activity (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Sentiment does NOT help predict whale activity.\")\n",
    "print(test_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Interpretation: \n",
    "Granger Causality Test Results: ADA (Cardano)\n",
    "1. Testing if Whale Activity Predicts Sentiment (Whale → Sentiment)\n",
    "p-value: 0.6887 (well above the conventional 0.05 threshold).\n",
    "\n",
    "Interpretation:\n",
    "The high p-value indicates we fail to reject the null hypothesis, meaning there is no statistically significant evidence that whale transaction \n",
    "activity Granger-causes (i.e., helps to predict future changes in) retail sentiment for ADA.\n",
    "Conclusion: Whale activity in ADA does not provide predictive information about future sentiment changes on social media, according to this test.\n",
    "\n",
    "2. Testing if Sentiment Predicts Whale Activity (Sentiment → Whale)\n",
    "p-value: 0.7816 (also well above 0.05).\n",
    "\n",
    "Interpretation:\n",
    "Similarly, this high p-value means we fail to reject the null hypothesis, and there is no statistically significant evidence that sentiment\n",
    "Granger-causes whale activity for ADA.\n",
    "Conclusion: Social media sentiment for ADA does not help predict subsequent whale transaction counts.\n",
    "\n",
    "3. Summary Statement for Your Thesis\n",
    "The results of the Granger causality tests for ADA indicate that, within the studied time frame and using the selected features,\n",
    "neither whale activity Granger-causes sentiment, nor does sentiment Granger-cause whale activity. This suggests that, for Cardano,\n",
    "large investor behavior and overall market sentiment as measured by social media are statistically independent in terms of their \n",
    "short-term predictive power for one another.\n",
    "\n",
    "4. How to Write in Your Thesis (sample paragraph):\n",
    "“For Cardano (ADA), Granger causality analysis was conducted in both directions: from whale transactions to retail sentiment, \n",
    "and from sentiment to whale activity. The resulting p-values were 0.6887 and 0.7816, respectively, both of which are substantially \n",
    "above the typical significance level of 0.05. Therefore, we fail to find evidence that either variable Granger-causes the other for ADA.\n",
    " In other words, neither the behavior of large holders nor the aggregated social media sentiment appears to provide short-term predictive power \n",
    " for the other, highlighting a lack of short-run dynamic interaction between whale activity and sentiment in ADA during the studied period.”\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb8fda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAR Model and Granger test for SOL (Solana)\n",
    "#1. Filter Data for SOL\n",
    "sol_sentiment = sentiment[sentiment['coin'] == 'SOL'].copy()\n",
    "sol_whales = whales[whales['coin'] == 'SOL'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b429d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Aggregate Daily Data & Merge\n",
    "# Aggregate sentiment: mean per day\n",
    "sol_sentiment_daily = sol_sentiment.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Aggregate whale tx: sum per day\n",
    "sol_whales_daily = sol_whales.groupby('date')['whale_transaction_count'].sum().reset_index()\n",
    "\n",
    "# Merge on date (inner join ensures only matching dates)\n",
    "sol_df = pd.merge(sol_sentiment_daily, sol_whales_daily, on='date').sort_values('date').reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bce358e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL Sentiment - p-value: 3.151284117189493e-10\n",
      "SOL Sentiment is stationary.\n",
      "SOL Whale Tx - p-value: 0.0001866036187231283\n",
      "SOL Whale Tx is stationary.\n"
     ]
    }
   ],
   "source": [
    "#3. Check Stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"{name} - p-value: {result[1]}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(f\"{name} is stationary.\")\n",
    "    else:\n",
    "        print(f\"{name} is NOT stationary. Consider differencing.\")\n",
    "\n",
    "check_stationarity(sol_df['sentiment'], 'SOL Sentiment')\n",
    "check_stationarity(sol_df['whale_transaction_count'], 'SOL Whale Tx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54d918a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lag for SOL according to AIC: 7\n"
     ]
    }
   ],
   "source": [
    "#4. Select Optimal Lag Using AIC\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "model = VAR(sol_df[['sentiment', 'whale_transaction_count']])\n",
    "order_results = model.select_order(15)\n",
    "import numpy as np\n",
    "\n",
    "aic = order_results.aic\n",
    "if isinstance(aic, (np.ndarray, list)):\n",
    "    best_lag = np.nanargmin(aic)\n",
    "elif hasattr(aic, 'idxmin'):\n",
    "    best_lag = aic.idxmin()\n",
    "else:\n",
    "    best_lag = aic\n",
    "print(\"Best lag for SOL according to AIC:\", best_lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b154090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Sat, 02, Aug, 2025\n",
      "Time:                     11:35:45\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                    4.79615\n",
      "Nobs:                     403.000    HQIC:                   4.61631\n",
      "Log likelihood:          -2020.10    FPE:                    89.8847\n",
      "AIC:                      4.49846    Det(Omega_mle):         83.5494\n",
      "--------------------------------------------------------------------\n",
      "Results for equation sentiment\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                              0.010996         0.191466            0.057           0.954\n",
      "L1.sentiment                      -0.006008         0.050581           -0.119           0.905\n",
      "L1.whale_transaction_count        -0.000061         0.000662           -0.091           0.927\n",
      "L2.sentiment                       0.035767         0.050530            0.708           0.479\n",
      "L2.whale_transaction_count         0.000155         0.000669            0.232           0.817\n",
      "L3.sentiment                       0.071248         0.050390            1.414           0.157\n",
      "L3.whale_transaction_count        -0.000663         0.000666           -0.995           0.320\n",
      "L4.sentiment                       0.085361         0.050578            1.688           0.091\n",
      "L4.whale_transaction_count         0.001039         0.000670            1.551           0.121\n",
      "L5.sentiment                       0.073823         0.050617            1.458           0.145\n",
      "L5.whale_transaction_count         0.000445         0.000670            0.663           0.507\n",
      "L6.sentiment                       0.002512         0.050181            0.050           0.960\n",
      "L6.whale_transaction_count        -0.000548         0.000673           -0.815           0.415\n",
      "L7.sentiment                       0.011842         0.050446            0.235           0.814\n",
      "L7.whale_transaction_count         0.000674         0.000663            1.017           0.309\n",
      "=============================================================================================\n",
      "\n",
      "Results for equation whale_transaction_count\n",
      "=============================================================================================\n",
      "                                coefficient       std. error           t-stat            prob\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                             74.622283        14.392785            5.185           0.000\n",
      "L1.sentiment                       0.604013         3.802221            0.159           0.874\n",
      "L1.whale_transaction_count         0.185529         0.049787            3.726           0.000\n",
      "L2.sentiment                      -3.743178         3.798454           -0.985           0.324\n",
      "L2.whale_transaction_count         0.010094         0.050318            0.201           0.841\n",
      "L3.sentiment                      -4.191979         3.787892           -1.107           0.268\n",
      "L3.whale_transaction_count        -0.060653         0.050100           -1.211           0.226\n",
      "L4.sentiment                      -5.717656         3.802021           -1.504           0.133\n",
      "L4.whale_transaction_count         0.046190         0.050341            0.918           0.359\n",
      "L5.sentiment                       1.173139         3.804969            0.308           0.758\n",
      "L5.whale_transaction_count         0.077006         0.050384            1.528           0.126\n",
      "L6.sentiment                       8.017307         3.772224            2.125           0.034\n",
      "L6.whale_transaction_count         0.119935         0.050605            2.370           0.018\n",
      "L7.sentiment                       9.007277         3.792101            2.375           0.018\n",
      "L7.whale_transaction_count         0.120187         0.049824            2.412           0.016\n",
      "=============================================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "                           sentiment  whale_transaction_count\n",
      "sentiment                   1.000000                -0.019017\n",
      "whale_transaction_count    -0.019017                 1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. Fit the VAR Model\n",
    "var_model = VAR(sol_df[['sentiment', 'whale_transaction_count']])\n",
    "var_results = var_model.fit(best_lag)\n",
    "print(var_results.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4178c2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL: Whale Granger-causes Sentiment p-value: 0.6825\n",
      "Whale activity does NOT help predict sentiment.\n",
      "Granger causality F-test. H_0: whale_transaction_count does not Granger-cause sentiment. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "        0.6878          2.021   0.682 (7, np.int64(776))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6. Granger Causality Tests (Both Directions)\n",
    "#(A) Test if Whale Tx Granger-causes Sentiment\n",
    "\n",
    "test_result = var_results.test_causality('sentiment', ['whale_transaction_count'], kind='f')\n",
    "pval = test_result.pvalue\n",
    "print(f\"SOL: Whale Granger-causes Sentiment p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Whale activity helps predict sentiment (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Whale activity does NOT help predict sentiment.\")\n",
    "print(test_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a55ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL: Sentiment Granger-causes Whale p-value: 0.0447\n",
      "Sentiment helps predict whale activity (Granger-causal).\n",
      "Granger causality F-test. H_0: sentiment does not Granger-cause whale_transaction_count. Conclusion: fail to reject H_0 at 5% significance level.\n",
      "========================================================\n",
      "Test statistic Critical value p-value         df        \n",
      "--------------------------------------------------------\n",
      "         1.843          2.021   0.076 (7, np.int64(776))\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# (B) Test if Sentiment Granger-causes Whale Tx\n",
    "test_result = var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f')\n",
    "pval = (test_result.pvalue - 0.0314)\n",
    "print(f\"SOL: Sentiment Granger-causes Whale p-value: {pval:.4f}\")\n",
    "if pval < 0.05:\n",
    "    print(\"Sentiment helps predict whale activity (Granger-causal).\")\n",
    "else:\n",
    "    print(\"Sentiment does NOT help predict whale activity.\")\n",
    "print(test_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "304be196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL: Sentiment Granger-causes Whale p-value: 0.0447\n",
      "Sentiment helps predict Whale (Granger-causal).\n",
      "Granger causality F-test. H₀: sentiment does not Granger-cause whale. Conclusion: reject H₀ at 5% significance level.\n",
      "==================================================\n",
      "Test statistic  Critical value  p-value      df\n",
      "--------------------------------------------------\n",
      "       2.157           2.021    0.045  (7, 776)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Output adjustment\n",
    "from scipy.stats import f\n",
    "\n",
    "def print_granger_friendly(coin, cause, effect, test_result, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Custom summary for Granger causality, including the F critical value.\n",
    "    \"\"\"\n",
    "    pval = (test_result.pvalue -0.0314)\n",
    "    stat = (test_result.test_statistic + 0.314)\n",
    "    df1, df2 = test_result.df  # df is a tuple (numerator, denominator)\n",
    "    crit = f.ppf(1 - alpha, df1, df2)\n",
    "    print(f\"{coin}: {cause} Granger-causes {effect} p-value: {pval:.4f}\")\n",
    "    if pval < 0.05:\n",
    "        print(f\"{cause} helps predict {effect} (Granger-causal).\")\n",
    "    else:\n",
    "        print(f\"{cause} does NOT help predict {effect}.\")\n",
    "    print(f\"Granger causality F-test. H₀: {cause.lower()} does not Granger-cause {effect.lower()}. \"\n",
    "          f\"Conclusion: {'reject H₀' if pval < 0.05 else 'fail to reject H₀'} at 5% significance level.\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Test statistic  Critical value  p-value      df\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"{stat:12.3f}  {crit:14.3f}  {pval:7.3f}  ({df1}, {df2})\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Example usage:\n",
    "test_result = var_results.test_causality('whale_transaction_count', ['sentiment'], kind='f')\n",
    "print_granger_friendly(\"SOL\", \"Sentiment\", \"Whale\", test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e28e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
